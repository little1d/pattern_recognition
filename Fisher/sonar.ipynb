{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ucimlrepo pandas numpy scikit-learn matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集导入，并将 y 设置为 0/1 值  后续封装为 load_data 函数\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "import numpy as np\n",
    "\n",
    "# fetch dataset \n",
    "sonar = fetch_ucirepo(id=151) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = sonar.data.features \n",
    "y = sonar.data.targets \n",
    "X.head()\n",
    "y.head()\n",
    "y_c = np.unique(y)\n",
    "y = np.array(y)\n",
    "for i in range(len(y_c)):\n",
    "    y[y == y_c[i]] = i\n",
    "y = y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['M' 'R'] \n",
      " [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "print(y_c, '\\n',y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k_fold_cross_validation: (167, 60), (41, 60), (167, 1), (41, 1)\n",
      "leave_one_out_cross_validation: (207, 60), (1, 60), (207, 1), (1, 1)\n",
      "random_split: (145, 60), (63, 60), (145, 1), (63, 1)\n"
     ]
    }
   ],
   "source": [
    "# 测试数据切分是否正常\n",
    "\n",
    "from utils import random_split, k_fold_cross_validation, leave_one_out_cross_validation\n",
    "\n",
    "X_train, X_test, y_train, y_test = k_fold_cross_validation(X, y, 5)\n",
    "print(f'k_fold_cross_validation: {X_train.shape}, {X_test.shape}, {y_train.shape}, {y_test.shape}')\n",
    "\n",
    "X_train, X_test, y_train, y_test = leave_one_out_cross_validation(X, y)\n",
    "print(f'leave_one_out_cross_validation: {X_train.shape}, {X_test.shape}, {y_train.shape}, {y_test.shape}')\n",
    "\n",
    "X_train, X_test, y_train, y_test = random_split(X, y, 0.3)\n",
    "print(f'random_split: {X_train.shape}, {X_test.shape}, {y_train.shape}, {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   9.85291837,   13.91528594,  -28.49420217,   23.88164391,\n",
       "         -1.48449585,   -3.38461824,   -2.41717141,  -10.36275757,\n",
       "          8.48741066,   -1.87055107,    0.3503974 ,    4.62850243,\n",
       "          8.0712496 ,   -2.36112895,    1.05290153,   -0.26922331,\n",
       "        -10.81153439,   11.44736519,   -4.84416734,    3.97670198,\n",
       "         -4.69482121,    7.13861357,   -6.45080804,    9.37857195,\n",
       "         -4.97628065,   -2.38393811,    4.22247314,   -1.67921765,\n",
       "         -1.66607956,    8.29067496,  -14.6780713 ,   11.1227271 ,\n",
       "         -4.41726343,   -4.32054055,    8.90883885,   -6.39181502,\n",
       "         -0.73085779,   -0.45171624,    4.7879488 ,   -4.63749772,\n",
       "          4.97107301,   -6.10850118,    6.45473754,   -3.68378809,\n",
       "          1.64023974,   -2.41374896,    9.63242842,    4.28353446,\n",
       "         24.31740735,  -44.72937524,  -25.0832603 ,   32.55320885,\n",
       "         51.25159363,   39.61450524, -106.40022208,  -23.06211665,\n",
       "         53.10212203,   41.73883413,   38.41447393,  -58.88992507])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train[0:3,:2]\n",
    "np.mean(X_test[1,:])\n",
    "cov_m = np.zeros(X_test[1,:].shape[0])\n",
    "np.mean(X_test,axis=0).shape\n",
    "np.cov(X_test.T).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(y_test): 63\n",
      "count: 45\n",
      "accuracy: 0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "W, u1, u2 = fisher_discriminant_analysis(X_train, y_train)\n",
    "y_pred = np.zeros(len(y_test))\n",
    "for i in range(len(y_test)):\n",
    "    y_pred[i] = judge_sample(X_test[i,:], W, u1, u2)\n",
    "print(\"len(y_test):\", len(y_test))\n",
    "count = 0\n",
    "for i in range(len(y_test)):\n",
    "    # print(f\"y_pred[i]:{y_pred[i]}, y_test[i]:{y_test[i]}\")\n",
    "    # print(y_pred[i] == y_test[i])\n",
    "    if y_pred[i] == y_test[i]:\n",
    "        count+=1\n",
    "print(\"count:\", count)\n",
    "accuracy = count / len(y_test)\n",
    "print(\"accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.02732189e+13,  2.85425258e+12, -2.04736785e+12, -1.20918418e+12,\n",
       "       -5.67547689e+11, -1.66496288e+11,  4.26959260e+11, -4.21257668e+12,\n",
       "        9.13392888e+11, -8.94838500e+11, -1.02919094e+12,  5.18496695e+12,\n",
       "        1.78190525e+12, -1.65684709e+12,  1.07896784e+12,  2.58500777e+12,\n",
       "        3.02741365e+11,  1.49890795e+12, -3.23973244e+12,  5.77306652e+11,\n",
       "        2.55351218e+12,  2.70615206e+11, -3.40955687e+11, -1.77194919e+12,\n",
       "        5.01047589e+11, -8.85005790e+11, -2.25006924e+10,  2.52595909e+12,\n",
       "        4.25269821e+12,  1.02215028e+11, -8.50023886e+10, -1.10629632e+12,\n",
       "       -8.21590014e+10, -3.63809132e+12, -3.65358513e+12, -2.35739869e+12,\n",
       "        1.03529306e+12,  9.39417299e+10,  7.39624705e+11, -8.12166267e+11,\n",
       "        2.55200722e+12,  1.48629182e+12,  9.34577898e+10,  3.96536269e+12,\n",
       "       -3.43720285e+12, -1.76070176e+12, -1.42757683e+12, -1.86152733e+12,\n",
       "        1.24927801e+11, -2.25982160e+11, -4.46464783e+11, -3.99772688e+11,\n",
       "       -3.84485191e+11,  3.17051807e+11,  1.23392139e+11, -2.42001830e+11,\n",
       "       -2.49579536e+10,  7.31348291e+10, -1.09738606e+11,  1.08905357e+11])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def judge_sample(sample, w, u1, u2):\n",
    "    # sample 属于 c1 返回 False，属于 c2 返回 True\n",
    "    center_1 = np.dot(w.T, u1)\n",
    "    center_2 = np.dot(w.T, u2)\n",
    "    pos = np.dot(w.T, sample)\n",
    "    return abs(pos - center_1) > abs(pos - center_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = fisher_discriminant_analysis(X_train, y_train)\n",
    "index1 = np.array(y[y['class'] == 0].index) # 获取类别为'0'的 index\n",
    "index2 = np.array(y[y['class'] == 1].index) # 获取类别为'1'的 index\n",
    "_, u1 = cal_cov_and_avg(X.iloc[index1])\n",
    "_, u2 = cal_cov_and_avg(X.iloc[index2])\n",
    "y_pred = np.zeros(len(y_test))\n",
    "for i in range(len(y_test)):\n",
    "    y_pred[i] = judge_sample(X_test.to_numpy()[i], W, u1, u2)\n",
    "accuracy = np.sum(y_pred == y_test) / len(y_test)\n",
    "print(\"accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(W.T, u1)\n",
    "np.dot(W.T, u2)\n",
    "pos = np.dot(W.T, X_test.to_numpy()[0])\n",
    "pos\n",
    "pos - np.dot(W.T, u1)\n",
    "res = judge_sample(X_test.to_numpy()[0], W, u1, u2)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fisher_discriminant_analysis(X, y):\n",
    "    index1 = np.where(y == 0)[0] # 获取类别为'0'的 index\n",
    "    index2 = np.where(y == 1)[0] # 获取类别为'1'的 index\n",
    "    con_1, u1 = cal_cov_and_avg(X.iloc[index1])\n",
    "    con_2, u2 = cal_cov_and_avg(X.iloc[index2])\n",
    "    S_W = con_1 + con_2\n",
    "    u, s, v = np.linalg.svd(S_W)\n",
    "    # 投影方向向量wß\n",
    "    S_W_inv = np.dot(np.dot(v.T, np.linalg.inv(np.diag(s))), u.T)\n",
    "    W = np.dot(S_W_inv,u1 - u2)\n",
    "    return W\n",
    "\n",
    "\n",
    "\n",
    "W = fisher_discriminant_analysis(X_train, y_train)\n",
    "index1 = np.where(y_train == 0)[0] # 获取类别为'0'的 index\n",
    "index2 = np.where(y_train == 1)[0] # 获取类别为'1'的 index\n",
    "_, u1 = cal_cov_and_avg(X_train.iloc[index1])\n",
    "_, u2 = cal_cov_and_avg(X_train.iloc[index2])\n",
    "# y_pred = np.zeros(len(y_test))\n",
    "# for i in range(len(y_test)):\n",
    "#     y_pred[i] = judge_sample(X_test.to_numpy()[i], W, u1, u2)\n",
    "# accuracy = np.sum(y_pred == y_test) / len(y_test)\n",
    "# print(\"accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cross_validation(X, y, n_splits, random_state=42):\n",
    "    X.to_numpy()\n",
    "    y.to_numpy()\n",
    "    skf = StratifiedKFold(n_splits=n_splits,random_state=random_state,shuffle=True)\n",
    "    skf.get_n_splits(X,y)\n",
    "    for _, (train_index, test_index) in enumerate(skf.split(X,y)):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = k_fold_cross_validation(X, y,n_splits=3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "skf.get_n_splits(X, y)\n",
    "for _, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_data('sonar')\n",
    "y_c = np.unique(y)\n",
    "X.to_numpy()\n",
    "y = np.array(y)\n",
    "for i in range(len(y_c)):\n",
    "    y[y == y_c[i]] = i\n",
    "y = y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(y)\n",
    "type(X.values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moshi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
